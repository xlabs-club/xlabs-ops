# -- Number of replicas
replicaCount: 1

# Knative configuration
knative:
  # -- Enable Knative integration
  enabled: false

# Docker image
image:
  # -- Docker image registry
  repository: reg.firstshare.cn/docker.io.proxy/ollama/ollama

  # -- Docker pull policy
  # pullPolicy: IfNotPresent

  # -- Docker image tag, overrides the image tag whose default is the chart appVersion.
  # tag: "0.5.12"

# Ollama parameters
ollama:
  gpu:
    # -- Enable GPU integration
    enabled: false

  models:
    # -- List of models to pull at container startup
    # The more you add, the longer the container will take to start if models are not present
    # pull:
    #  - llama2
    #  - mistral
    pull: 
      - nomic-embed-text
      - mxbai-embed-large
      # - huggingface.co/BAAI/bge-reranker-v2-m3

    # -- List of models to load in memory at container startup
    # run:
    #  - llama2
    #  - mistral
    # run: 
    #   - huggingface.co/BAAI/bge-reranker-v2-m3
    # -- List of models to create at container startup, there are two options
    # 1. Create a raw model
    # 2. Load a model from configMaps, configMaps must be created before and are loaded as volume in "/models" directory.
    # create:
    #  - name: llama3.1-ctx32768
    #    configMapRef: my-configmap
    #    configMapKeyRef: configmap-key
    #  - name: llama3.1-ctx32768
    #    template: |
    #      FROM llama3.1
    #      PARAMETER num_ctx 32768
    create: []

  # -- Add insecure flag for pulling at container startup
  insecure: true

  # -- Override ollama-data volume mount path, default: "/root/.ollama"
  mountPath: ""

# Service account
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
serviceAccount:
  # -- Specifies whether a service account should be created
  create: true

# -- Specify runtime class
runtimeClassName: ""

# Configure Service
service:

  # -- Service type
  type: ClusterIP

  # -- Service port
  port: 11434

  # -- Service node port when service type is 'NodePort'
  nodePort: 31434

# Configure resource requests and limits
# ref: http://kubernetes.io/docs/user-guide/compute-resources/
resources:
  # -- Pod requests
  requests: {}
    # Memory request
    # memory: 4096Mi

    # CPU request
    # cpu: 2000m

  # -- Pod limit
  limits: {}
    # Memory limit
    # memory: 8192Mi

    # CPU limit
    # cpu: 4000m

# Configure extra options for liveness probe
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
livenessProbe:
  # -- Enable livenessProbe
  enabled: true

  # -- Request path for livenessProbe
  path: /

  # -- Initial delay seconds for livenessProbe
  initialDelaySeconds: 60

  # -- Period seconds for livenessProbe
  periodSeconds: 10

  # -- Timeout seconds for livenessProbe
  timeoutSeconds: 5

  # -- Failure threshold for livenessProbe
  failureThreshold: 6

  # -- Success threshold for livenessProbe
  successThreshold: 1

# Configure extra options for readiness probe
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
readinessProbe:
  # -- Enable readinessProbe
  enabled: true

  # -- Request path for readinessProbe
  path: /

  # -- Initial delay seconds for readinessProbe
  initialDelaySeconds: 60

  # -- Period seconds for readinessProbe
  periodSeconds: 5

  # -- Timeout seconds for readinessProbe
  timeoutSeconds: 3

  # -- Failure threshold for readinessProbe
  failureThreshold: 6

  # -- Success threshold for readinessProbe
  successThreshold: 1

# -- Additional arguments on the output Deployment definition.
extraArgs: []

# -- Additional environments variables on the output Deployment definition.
# For extra OLLAMA env, please refer to https://github.com/ollama/ollama/blob/main/envconfig/config.go
extraEnv: []
#  - name: OLLAMA_DEBUG
#    value: "1"

# Enable persistence using Persistent Volume Claims
# ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
persistentVolume:
  # -- Enable persistence using PVC
  enabled: true

  # -- Ollama server data Persistent Volume access modes
  # Must match those of existing PV or dynamic provisioner
  # Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  accessModes:
    - ReadWriteOnce

  # -- Ollama server data Persistent Volume size
  size: 30Gi

  # -- Ollama server data Persistent Volume Storage Class
  # If defined, storageClassName: <storageClass>
  # If set to "-", storageClassName: "", which disables dynamic provisioning
  # If undefined (the default) or set to null, no storageClassName spec is
  # set, choosing the default provisioner.  (gp2 on AWS, standard on
  # GKE, AWS & OpenStack)
  storageClass: ""


